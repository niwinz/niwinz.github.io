<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>niwi.nz : Optimizing server for heavy load wsgi application</title>
    <meta name=viewport content='width=200, initial-scale=1'>

  <meta name="desciption" content="Many times, we only care to optimize the database, nginx or WSGI server, and often is more than enough. But, when you have a web application that must be able to scale and support over 2000 concurrent users, this is totally insufficient. Here comes the part where we have to optimize the operating system, such as kernel parameters for TCP/IP stack, and more. File descriptor limit As a first step, we need to accept a lot of http requests. So we have to adapt nginx settings and operating system..." />
    <meta name="author" content="Andrey Antukh" />

    <link rel="stylesheet" href="https://niwi.nz/theme/css/main.css" />

      <link href="https://niwi.nz/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="niwi.nz Atom Feed" />


  </head>

  <body>
    <main>
      <div class="entry">
  <header>
    <a href="https://niwi.nz"><small>(return to home)</small></a>
    <h1>
      <a href="https://niwi.nz/2013/03/13/optimizing-server-for-heavy-load-django-application/" id="page-title">Optimizing server for heavy load wsgi application</a>
    </h1>
    <div class="article-meta">
        <small class="time">
          Date:
          <time datetime="2013-03-13T00:00:00+00:00">
            Wed 13 March 2013
          </time>
        </small>
      <br />
      <small class="tags">
        Tags:
          <a href="https://niwi.nz/tag/django.html">django,           </a>
          <a href="https://niwi.nz/tag/nginx.html">nginx,           </a>
          <a href="https://niwi.nz/tag/gunicorn.html">gunicorn          </a>
      </small>

      <br />
      <small class="tags">
        Author:
          <span>Andrey Antukh</span>      </small>
    </div>
  </header>
  <article>
    <div id="article-content">
      <p>Many times, we only care to optimize the database, nginx or WSGI server, and often is more than enough.
But, when you have a web application that must be able to scale and support over 2000 concurrent users,
this is totally insufficient.</p>
<p>Here comes the part where we have to optimize the operating system, such as kernel parameters for TCP/IP
stack, and more.</p>
<div class="section" id="file-descriptor-limit">
<h2>File descriptor limit</h2>
<p>As a first step, we need to accept a lot of http requests. So we have to adapt nginx settings and operating
system settings (linux) for their requirements.</p>
<p>We know that each incoming socket is a file descriptor used. And by default a normal user has a limit of
1024 file descriptors. To accept many requests, we need to modify this parameter on both: nginx config and
linux kernel parameters.</p>
<p>For modify the limit of fd's for a users, your need modify <tt class="docutils literal">/etc/security/limits.conf</tt> file, and add
these lines:</p>
<div class="highlight"><pre><span></span># For nginx, if your nginx runs with
# other user, put its instead of www-data
www-data   soft    nofile      256000
www-data   hard    nofile      260000

# If you wsgi server runs as user
@users      soft    nofile      256000
@users      hard    nofile      260000

# Puts nofile limits equals for all users
#*          soft    nofile      256000
#*          hard    nofile      260000
</pre></div>
<p>In rare cases, the kernel has a hard limit for open files vert low, and, if you put open file number
hight of kernel hight limit on limits.conf, will no have any effect. In this case, you need increase kernel
limit midifying <tt class="docutils literal"><span class="pre">fs.file-max</span></tt>.</p>
<p>On my system the kernel hard limit is very big and I have not worry about it.</p>
<div class="highlight"><pre><span></span><span class="go">[5.0.2]root@niwi:~niwi# sysctl fs.file-max</span>
<span class="go">fs.file-max = 398897</span>
</pre></div>
<p>Otherwhise, set a new value for this kernel paramer on <strong>/etc/sysctl.conf</strong>:</p>
<div class="highlight"><pre><span></span>fs.file-max=260000
</pre></div>
<p>After this, you can modify a nginx configuration, and put a accept connection parameter to a huge
number of connections:</p>
<div class="highlight"><pre><span></span><span class="c1"># /etc/nginx/nginx.conf</span>
<span class="k">user</span><span class="w"> </span><span class="s">www-data</span><span class="p">;</span><span class="w"></span>

<span class="c1"># this number really depends of number</span>
<span class="c1"># of cpu/cores on your server</span>
<span class="k">worker_processes</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span><span class="w"></span>
<span class="k">pid</span><span class="w"> </span><span class="s">/var/run/nginx.pid</span><span class="p">;</span><span class="w"></span>

<span class="k">events</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kn">worker_connections</span><span class="w"> </span><span class="mi">4069</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kn">use</span><span class="w"> </span><span class="s">epoll</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="k">http</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kn">sendfile</span><span class="w"> </span><span class="no">on</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kn">tcp_nopush</span><span class="w"> </span><span class="no">on</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kn">tcp_nodelay</span><span class="w"> </span><span class="no">on</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># Large values reduce performance</span>
<span class="w">    </span><span class="c1"># for requests to wsgi server.</span>
<span class="w">    </span><span class="kn">keepalive_timeout</span><span class="w"> </span><span class="mi">15</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kn">types_hash_max_size</span><span class="w"> </span><span class="mi">2048</span><span class="p">;</span><span class="w"></span>

<span class="w">    </span><span class="c1"># [...]</span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<div class="section" id="connection-backlog">
<h2>Connection backlog</h2>
<p>Okay, We are able to have many open sockets, but your kernel has enough queue size to accept them? By
default, linux kernel has very small queue for connections:</p>
<div class="highlight"><pre><span></span><span class="go">[5.0.2]root@niwi:~niwi# sysctl net.core.somaxconn</span>
<span class="go">net.core.somaxconn = 128</span>
</pre></div>
<p>For heavy load web server, this is a very bad configuration. 65536 is a possible good value for
this kernel parameter.</p>
<div class="highlight"><pre><span></span># sysctl.conf
net.core.somaxconn=65536

# other minor tuning
net.core.netdev_max_backlog=2500
net.ipv4.tcp_max_syn_backlog=2500
net.ipv4.tcp_keepalive_time=300
</pre></div>
<p>Additionally, you can enlarge local port range:</p>
<div class="highlight"><pre><span></span># sysctl.conf
net.ipv4.ip_local_port_range=1024 65535
</pre></div>
</div>
<div class="section" id="related-links">
<h2>Related links</h2>
<ul class="simple">
<li><a class="reference external" href="http://itresident.com/nginx/nginx-and-php-fpm-for-heavy-load-wordpress-web-server-with-high-traffic-2000-concurrent-connections/">http://itresident.com/nginx/nginx-and-php-fpm-for-heavy-load-wordpress-web-server-with-high-traffic-2000-concurrent-connections/</a></li>
<li><a class="reference external" href="http://nichol.as/benchmark-of-python-web-servers">http://nichol.as/benchmark-of-python-web-servers</a></li>
</ul>
</div>

    </div>
  </article>
      </div>
      </div>
    </main>
  </body>
</html>